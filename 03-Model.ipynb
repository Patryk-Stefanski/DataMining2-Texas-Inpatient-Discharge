{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad8427b-5ce2-4e9d-a4e6-c4772a0e398a",
   "metadata": {},
   "source": [
    "# Texas Inpatient Discharg - Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1772edba",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "796c44f3-cf1f-4a3a-8d9c-3939c461824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from scipy import stats\n",
    "import yaml, time, sys, os, glob\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "DATASET = \"Texas_Inpatient_Discharge\"\n",
    "SPLIT_TRAINING = True\n",
    "DEBUG = False\n",
    "SEED = 42\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "if COLAB:\n",
    "    ROOT = f\"/content/gdrive/MyDrive/datasets/{DATASET.replace(' ','_')}/\"\n",
    "else:\n",
    "    ROOT = \"./\"\n",
    "\n",
    "import my_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "869b3ea7-8b69-46c1-8be0-1182f803881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder , StandardScaler\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, RFECV\n",
    "\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier,StackingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d124959",
   "metadata": {},
   "source": [
    "### Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "848c1538-5604-4341-ab13-414d9d5756ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199939, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE_OF_ADMISSION</th>\n",
       "      <th>SOURCE_OF_ADMISSION</th>\n",
       "      <th>PAT_STATE</th>\n",
       "      <th>PAT_COUNTRY</th>\n",
       "      <th>PUBLIC_HEALTH_REGION</th>\n",
       "      <th>SEX_CODE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>ADMIT_WEEKDAY</th>\n",
       "      <th>ADMITTING_DIAGNOSIS</th>\n",
       "      <th>PRINC_DIAG_CODE</th>\n",
       "      <th>POA_PRINC_DIAG_CODE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>PROVIDER_NAME_col_0</th>\n",
       "      <th>PROVIDER_NAME_col_1</th>\n",
       "      <th>PROVIDER_NAME_col_2</th>\n",
       "      <th>PROVIDER_NAME_col_3</th>\n",
       "      <th>PROVIDER_NAME_col_4</th>\n",
       "      <th>PROVIDER_NAME_col_5</th>\n",
       "      <th>PROVIDER_NAME_col_6</th>\n",
       "      <th>COUNTY_col_0</th>\n",
       "      <th>COUNTY_col_1</th>\n",
       "      <th>COUNTY_col_2</th>\n",
       "      <th>COUNTY_col_3</th>\n",
       "      <th>COUNTY_col_4</th>\n",
       "      <th>COUNTY_col_5</th>\n",
       "      <th>COUNTY_col_6</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_0</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_1</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_2</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_3</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_4</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_5</th>\n",
       "      <th>ADMITTING_DIAGNOSIS_col_6</th>\n",
       "      <th>PRINC_DIAG_CODE_col_0</th>\n",
       "      <th>PRINC_DIAG_CODE_col_1</th>\n",
       "      <th>PRINC_DIAG_CODE_col_2</th>\n",
       "      <th>PRINC_DIAG_CODE_col_3</th>\n",
       "      <th>PRINC_DIAG_CODE_col_4</th>\n",
       "      <th>PRINC_DIAG_CODE_col_5</th>\n",
       "      <th>PRINC_DIAG_CODE_col_6</th>\n",
       "      <th>POA_OTH_DIAG_CODE_COUNT</th>\n",
       "      <th>POA_E_CODE_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>992358</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>03</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>78650</td>\n",
       "      <td>78650</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900799</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>11</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7804</td>\n",
       "      <td>4359</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770151</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>42731</td>\n",
       "      <td>42731</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762640</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>07</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>78959</td>\n",
       "      <td>07070</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896831</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>08</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>V3000</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TYPE_OF_ADMISSION SOURCE_OF_ADMISSION PAT_STATE PAT_COUNTRY  \\\n",
       "992358                 1                   1        TX          US   \n",
       "900799                 1                   1        TX          US   \n",
       "770151                 1                   1        TX          US   \n",
       "762640                 1                   1        TX          US   \n",
       "896831                 4                   5        TX          US   \n",
       "\n",
       "       PUBLIC_HEALTH_REGION SEX_CODE RACE ETHNICITY ADMIT_WEEKDAY  \\\n",
       "992358                   03        M    4         2             6   \n",
       "900799                   11        F    4         1             4   \n",
       "770151                   11        M    4         1             6   \n",
       "762640                   07        F    2         1             6   \n",
       "896831                   08        M    4         2             4   \n",
       "\n",
       "       ADMITTING_DIAGNOSIS PRINC_DIAG_CODE POA_PRINC_DIAG_CODE TARGET  \\\n",
       "992358               78650           78650                   Y      2   \n",
       "900799                7804            4359                   Y      1   \n",
       "770151               42731           42731                   Y      1   \n",
       "762640               78959           07070                   Y      1   \n",
       "896831               V3000               U                 NaN      2   \n",
       "\n",
       "       PROVIDER_NAME_col_0 PROVIDER_NAME_col_1 PROVIDER_NAME_col_2  \\\n",
       "992358                   0                   0                   0   \n",
       "900799                   0                   0                   1   \n",
       "770151                   0                   0                   1   \n",
       "762640                   1                   0                   0   \n",
       "896831                   0                   0                   0   \n",
       "\n",
       "       PROVIDER_NAME_col_3 PROVIDER_NAME_col_4 PROVIDER_NAME_col_5  \\\n",
       "992358                   0                   0                   0   \n",
       "900799                   0                   0                   0   \n",
       "770151                   0                   0                   0   \n",
       "762640                   0                   0                   0   \n",
       "896831                   1                   0                   0   \n",
       "\n",
       "       PROVIDER_NAME_col_6 COUNTY_col_0 COUNTY_col_1 COUNTY_col_2  \\\n",
       "992358                   1            0            0            0   \n",
       "900799                   0            0            0            0   \n",
       "770151                   0            0            0            0   \n",
       "762640                   0            0            0            0   \n",
       "896831                   0            0            0            0   \n",
       "\n",
       "       COUNTY_col_3 COUNTY_col_4 COUNTY_col_5 COUNTY_col_6  \\\n",
       "992358            1            0            0            0   \n",
       "900799            0            0            1            0   \n",
       "770151            0            0            1            0   \n",
       "762640            0            1            0            0   \n",
       "896831            1            0            0            0   \n",
       "\n",
       "       ADMITTING_DIAGNOSIS_col_0 ADMITTING_DIAGNOSIS_col_1  \\\n",
       "992358                         0                         0   \n",
       "900799                         0                         0   \n",
       "770151                         0                         0   \n",
       "762640                         1                         0   \n",
       "896831                         0                         0   \n",
       "\n",
       "       ADMITTING_DIAGNOSIS_col_2 ADMITTING_DIAGNOSIS_col_3  \\\n",
       "992358                         0                         0   \n",
       "900799                         0                         1   \n",
       "770151                         0                         0   \n",
       "762640                         0                         0   \n",
       "896831                         0                         0   \n",
       "\n",
       "       ADMITTING_DIAGNOSIS_col_4 ADMITTING_DIAGNOSIS_col_5  \\\n",
       "992358                         0                         0   \n",
       "900799                         0                         0   \n",
       "770151                         0                         0   \n",
       "762640                         0                         0   \n",
       "896831                         0                         1   \n",
       "\n",
       "       ADMITTING_DIAGNOSIS_col_6 PRINC_DIAG_CODE_col_0 PRINC_DIAG_CODE_col_1  \\\n",
       "992358                         1                     0                     0   \n",
       "900799                         0                     0                     0   \n",
       "770151                         1                     0                     0   \n",
       "762640                         0                     0                     0   \n",
       "896831                         0                     0                     1   \n",
       "\n",
       "       PRINC_DIAG_CODE_col_2 PRINC_DIAG_CODE_col_3 PRINC_DIAG_CODE_col_4  \\\n",
       "992358                     0                     0                     0   \n",
       "900799                     0                     1                     0   \n",
       "770151                     0                     0                     0   \n",
       "762640                     0                     0                     0   \n",
       "896831                     0                     0                     0   \n",
       "\n",
       "       PRINC_DIAG_CODE_col_5 PRINC_DIAG_CODE_col_6  POA_OTH_DIAG_CODE_COUNT  \\\n",
       "992358                     0                     1                        8   \n",
       "900799                     0                     0                       14   \n",
       "770151                     0                     1                       11   \n",
       "762640                     0                     1                       13   \n",
       "896831                     0                     0                        0   \n",
       "\n",
       "        POA_E_CODE_COUNT  \n",
       "992358                 0  \n",
       "900799                 0  \n",
       "770151                 0  \n",
       "762640                 0  \n",
       "896831                 0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(f\"{ROOT}/data/df_train_preprocess_00_of_5.pkl\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79ee6699",
   "metadata": {},
   "source": [
    "#### Read In grading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57452a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5711/3517273426.py:1: DtypeWarning: Columns (4,8,18,91,92,93,94,95,96,97,98,103,105,106,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_grading = pd.read_csv(f\"{ROOT}/orig/grading.csv.gz\", compression=\"gzip\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 193)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD_ID</th>\n",
       "      <th>DISCHARGE</th>\n",
       "      <th>THCIC_ID</th>\n",
       "      <th>PROVIDER_NAME</th>\n",
       "      <th>TYPE_OF_ADMISSION</th>\n",
       "      <th>SOURCE_OF_ADMISSION</th>\n",
       "      <th>SPEC_UNIT_1</th>\n",
       "      <th>SPEC_UNIT_2</th>\n",
       "      <th>SPEC_UNIT_3</th>\n",
       "      <th>SPEC_UNIT_4</th>\n",
       "      <th>SPEC_UNIT_5</th>\n",
       "      <th>PAT_STATE</th>\n",
       "      <th>PAT_ZIP</th>\n",
       "      <th>PAT_COUNTRY</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>PUBLIC_HEALTH_REGION</th>\n",
       "      <th>PAT_STATUS</th>\n",
       "      <th>SEX_CODE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>ADMIT_WEEKDAY</th>\n",
       "      <th>PAT_AGE</th>\n",
       "      <th>FIRST_PAYMENT_SRC</th>\n",
       "      <th>SECONDARY_PAYMENT_SRC</th>\n",
       "      <th>TYPE_OF_BILL</th>\n",
       "      <th>TOTAL_CHARGES</th>\n",
       "      <th>TOTAL_NON_COV_CHARGES</th>\n",
       "      <th>TOTAL_CHARGES_ACCOMM</th>\n",
       "      <th>TOTAL_NON_COV_CHARGES_ACCOMM</th>\n",
       "      <th>TOTAL_CHARGES_ANCIL</th>\n",
       "      <th>TOTAL_NON_COV_CHARGES_ANCIL</th>\n",
       "      <th>POA_PROVIDER_INDICATOR</th>\n",
       "      <th>ADMITTING_DIAGNOSIS</th>\n",
       "      <th>PRINC_DIAG_CODE</th>\n",
       "      <th>POA_PRINC_DIAG_CODE</th>\n",
       "      <th>OTH_DIAG_CODE_1</th>\n",
       "      <th>POA_OTH_DIAG_CODE_1</th>\n",
       "      <th>OTH_DIAG_CODE_2</th>\n",
       "      <th>POA_OTH_DIAG_CODE_2</th>\n",
       "      <th>OTH_DIAG_CODE_3</th>\n",
       "      <th>POA_OTH_DIAG_CODE_3</th>\n",
       "      <th>OTH_DIAG_CODE_4</th>\n",
       "      <th>POA_OTH_DIAG_CODE_4</th>\n",
       "      <th>OTH_DIAG_CODE_5</th>\n",
       "      <th>POA_OTH_DIAG_CODE_5</th>\n",
       "      <th>OTH_DIAG_CODE_6</th>\n",
       "      <th>POA_OTH_DIAG_CODE_6</th>\n",
       "      <th>OTH_DIAG_CODE_7</th>\n",
       "      <th>POA_OTH_DIAG_CODE_7</th>\n",
       "      <th>OTH_DIAG_CODE_8</th>\n",
       "      <th>POA_OTH_DIAG_CODE_8</th>\n",
       "      <th>OTH_DIAG_CODE_9</th>\n",
       "      <th>POA_OTH_DIAG_CODE_9</th>\n",
       "      <th>OTH_DIAG_CODE_10</th>\n",
       "      <th>POA_OTH_DIAG_CODE_10</th>\n",
       "      <th>OTH_DIAG_CODE_11</th>\n",
       "      <th>POA_OTH_DIAG_CODE_11</th>\n",
       "      <th>OTH_DIAG_CODE_12</th>\n",
       "      <th>POA_OTH_DIAG_CODE_12</th>\n",
       "      <th>OTH_DIAG_CODE_13</th>\n",
       "      <th>POA_OTH_DIAG_CODE_13</th>\n",
       "      <th>OTH_DIAG_CODE_14</th>\n",
       "      <th>POA_OTH_DIAG_CODE_14</th>\n",
       "      <th>OTH_DIAG_CODE_15</th>\n",
       "      <th>POA_OTH_DIAG_CODE_15</th>\n",
       "      <th>OTH_DIAG_CODE_16</th>\n",
       "      <th>POA_OTH_DIAG_CODE_16</th>\n",
       "      <th>OTH_DIAG_CODE_17</th>\n",
       "      <th>POA_OTH_DIAG_CODE_17</th>\n",
       "      <th>OTH_DIAG_CODE_18</th>\n",
       "      <th>POA_OTH_DIAG_CODE_18</th>\n",
       "      <th>OTH_DIAG_CODE_19</th>\n",
       "      <th>POA_OTH_DIAG_CODE_19</th>\n",
       "      <th>OTH_DIAG_CODE_20</th>\n",
       "      <th>POA_OTH_DIAG_CODE_20</th>\n",
       "      <th>OTH_DIAG_CODE_21</th>\n",
       "      <th>POA_OTH_DIAG_CODE_21</th>\n",
       "      <th>OTH_DIAG_CODE_22</th>\n",
       "      <th>POA_OTH_DIAG_CODE_22</th>\n",
       "      <th>OTH_DIAG_CODE_23</th>\n",
       "      <th>POA_OTH_DIAG_CODE_23</th>\n",
       "      <th>OTH_DIAG_CODE_24</th>\n",
       "      <th>POA_OTH_DIAG_CODE_24</th>\n",
       "      <th>E_CODE_1</th>\n",
       "      <th>POA_E_CODE_1</th>\n",
       "      <th>E_CODE_2</th>\n",
       "      <th>POA_E_CODE_2</th>\n",
       "      <th>E_CODE_3</th>\n",
       "      <th>POA_E_CODE_3</th>\n",
       "      <th>E_CODE_4</th>\n",
       "      <th>POA_E_CODE_4</th>\n",
       "      <th>E_CODE_5</th>\n",
       "      <th>POA_E_CODE_5</th>\n",
       "      <th>E_CODE_6</th>\n",
       "      <th>POA_E_CODE_6</th>\n",
       "      <th>E_CODE_7</th>\n",
       "      <th>POA_E_CODE_7</th>\n",
       "      <th>E_CODE_8</th>\n",
       "      <th>POA_E_CODE_8</th>\n",
       "      <th>E_CODE_9</th>\n",
       "      <th>POA_E_CODE_9</th>\n",
       "      <th>E_CODE_10</th>\n",
       "      <th>POA_E_CODE_10</th>\n",
       "      <th>PRINC_SURG_PROC_CODE</th>\n",
       "      <th>PRINC_SURG_PROC_DAY</th>\n",
       "      <th>PRINC_ICD9_CODE</th>\n",
       "      <th>OTH_SURG_PROC_CODE_1</th>\n",
       "      <th>OTH_SURG_PROC_DAY_1</th>\n",
       "      <th>OTH_ICD9_CODE_1</th>\n",
       "      <th>OTH_SURG_PROC_CODE_2</th>\n",
       "      <th>OTH_SURG_PROC_DAY_2</th>\n",
       "      <th>OTH_ICD9_CODE_2</th>\n",
       "      <th>OTH_SURG_PROC_CODE_3</th>\n",
       "      <th>OTH_SURG_PROC_DAY_3</th>\n",
       "      <th>OTH_ICD9_CODE_3</th>\n",
       "      <th>OTH_SURG_PROC_CODE_4</th>\n",
       "      <th>OTH_SURG_PROC_DAY_4</th>\n",
       "      <th>OTH_ICD9_CODE_4</th>\n",
       "      <th>OTH_SURG_PROC_CODE_5</th>\n",
       "      <th>OTH_SURG_PROC_DAY_5</th>\n",
       "      <th>OTH_ICD9_CODE_5</th>\n",
       "      <th>OTH_SURG_PROC_CODE_6</th>\n",
       "      <th>OTH_SURG_PROC_DAY_6</th>\n",
       "      <th>OTH_ICD9_CODE_6</th>\n",
       "      <th>OTH_SURG_PROC_CODE_7</th>\n",
       "      <th>OTH_SURG_PROC_DAY_7</th>\n",
       "      <th>OTH_ICD9_CODE_7</th>\n",
       "      <th>OTH_SURG_PROC_CODE_8</th>\n",
       "      <th>OTH_SURG_PROC_DAY_8</th>\n",
       "      <th>OTH_ICD9_CODE_8</th>\n",
       "      <th>OTH_SURG_PROC_CODE_9</th>\n",
       "      <th>OTH_SURG_PROC_DAY_9</th>\n",
       "      <th>OTH_ICD9_CODE_9</th>\n",
       "      <th>OTH_SURG_PROC_CODE_10</th>\n",
       "      <th>OTH_SURG_PROC_DAY_10</th>\n",
       "      <th>OTH_ICD9_CODE_10</th>\n",
       "      <th>OTH_SURG_PROC_CODE_11</th>\n",
       "      <th>OTH_SURG_PROC_DAY_11</th>\n",
       "      <th>OTH_ICD9_CODE_11</th>\n",
       "      <th>OTH_SURG_PROC_CODE_12</th>\n",
       "      <th>OTH_SURG_PROC_DAY_12</th>\n",
       "      <th>OTH_ICD9_CODE_12</th>\n",
       "      <th>OTH_SURG_PROC_CODE_13</th>\n",
       "      <th>OTH_SURG_PROC_DAY_13</th>\n",
       "      <th>OTH_ICD9_CODE_13</th>\n",
       "      <th>OTH_SURG_PROC_CODE_14</th>\n",
       "      <th>OTH_SURG_PROC_DAY_14</th>\n",
       "      <th>OTH_ICD9_CODE_14</th>\n",
       "      <th>OTH_SURG_PROC_CODE_15</th>\n",
       "      <th>OTH_SURG_PROC_DAY_15</th>\n",
       "      <th>OTH_ICD9_CODE_15</th>\n",
       "      <th>OTH_SURG_PROC_CODE_16</th>\n",
       "      <th>OTH_SURG_PROC_DAY_16</th>\n",
       "      <th>OTH_ICD9_CODE_16</th>\n",
       "      <th>OTH_SURG_PROC_CODE_17</th>\n",
       "      <th>OTH_SURG_PROC_DAY_17</th>\n",
       "      <th>OTH_ICD9_CODE_17</th>\n",
       "      <th>OTH_SURG_PROC_CODE_18</th>\n",
       "      <th>OTH_SURG_PROC_DAY_18</th>\n",
       "      <th>OTH_ICD9_CODE_18</th>\n",
       "      <th>OTH_SURG_PROC_CODE_19</th>\n",
       "      <th>OTH_SURG_PROC_DAY_19</th>\n",
       "      <th>OTH_ICD9_CODE_19</th>\n",
       "      <th>OTH_SURG_PROC_CODE_20</th>\n",
       "      <th>OTH_SURG_PROC_DAY_20</th>\n",
       "      <th>OTH_ICD9_CODE_20</th>\n",
       "      <th>OTH_SURG_PROC_CODE_21</th>\n",
       "      <th>OTH_SURG_PROC_DAY_21</th>\n",
       "      <th>OTH_ICD9_CODE_21</th>\n",
       "      <th>OTH_SURG_PROC_CODE_22</th>\n",
       "      <th>OTH_SURG_PROC_DAY_22</th>\n",
       "      <th>OTH_ICD9_CODE_22</th>\n",
       "      <th>OTH_SURG_PROC_CODE_23</th>\n",
       "      <th>OTH_SURG_PROC_DAY_23</th>\n",
       "      <th>OTH_ICD9_CODE_23</th>\n",
       "      <th>OTH_SURG_PROC_CODE_24</th>\n",
       "      <th>OTH_SURG_PROC_DAY_24</th>\n",
       "      <th>OTH_ICD9_CODE_24</th>\n",
       "      <th>MS_MDC</th>\n",
       "      <th>MS_DRG</th>\n",
       "      <th>MS_GROUPER_VERSION_NBR</th>\n",
       "      <th>MS_GROUPER_ERROR_CODE</th>\n",
       "      <th>APR_MDC</th>\n",
       "      <th>APR_DRG</th>\n",
       "      <th>RISK_MORTALITY</th>\n",
       "      <th>ILLNESS_SEVERITY</th>\n",
       "      <th>APR_GROUPER_VERSION_NBR</th>\n",
       "      <th>APR_GROUPER_ERROR_CODE</th>\n",
       "      <th>ATTENDING_PHYSICIAN_UNIF_ID</th>\n",
       "      <th>OPERATING_PHYSICIAN_UNIF_ID</th>\n",
       "      <th>ENCOUNTER_INDICATOR</th>\n",
       "      <th>CERT_STATUS</th>\n",
       "      <th>FILLER_SPACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420132203333</td>\n",
       "      <td>2013Q4</td>\n",
       "      <td>145000</td>\n",
       "      <td>University Medical Center</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>79415</td>\n",
       "      <td>US</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>MC</td>\n",
       "      <td>ZZ</td>\n",
       "      <td>111</td>\n",
       "      <td>16352.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5555.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10797.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>V220</td>\n",
       "      <td>65981</td>\n",
       "      <td>Y</td>\n",
       "      <td>65911</td>\n",
       "      <td>N</td>\n",
       "      <td>64891</td>\n",
       "      <td>Y</td>\n",
       "      <td>66101</td>\n",
       "      <td>N</td>\n",
       "      <td>7923</td>\n",
       "      <td>N</td>\n",
       "      <td>V270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V0251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>734.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>766</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7300</td>\n",
       "      <td>0</td>\n",
       "      <td>1.054183e+09</td>\n",
       "      <td>1.401552e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220130397490</td>\n",
       "      <td>2013Q2</td>\n",
       "      <td>409000</td>\n",
       "      <td>John Peter Smith Hospital</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>76054</td>\n",
       "      <td>US</td>\n",
       "      <td>439.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>ZZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>30650.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20420.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>45386</td>\n",
       "      <td>45386</td>\n",
       "      <td>Y</td>\n",
       "      <td>4019</td>\n",
       "      <td>Y</td>\n",
       "      <td>V141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5259</td>\n",
       "      <td>Y</td>\n",
       "      <td>56400</td>\n",
       "      <td>Y</td>\n",
       "      <td>490</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>301</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7300</td>\n",
       "      <td>0</td>\n",
       "      <td>1.273456e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120137915430</td>\n",
       "      <td>2013Q1</td>\n",
       "      <td>331000</td>\n",
       "      <td>Baylor University Medical Center</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>75551</td>\n",
       "      <td>US</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>BL</td>\n",
       "      <td>CI</td>\n",
       "      <td>111</td>\n",
       "      <td>43770.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43188.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>Y</td>\n",
       "      <td>53085</td>\n",
       "      <td>Y</td>\n",
       "      <td>53081</td>\n",
       "      <td>Y</td>\n",
       "      <td>V1204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V1272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V1501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V0254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7871</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>605.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>708</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7300</td>\n",
       "      <td>0</td>\n",
       "      <td>1.318271e+09</td>\n",
       "      <td>1.318271e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420132272963</td>\n",
       "      <td>2013Q4</td>\n",
       "      <td>117100</td>\n",
       "      <td>Texas Childrens Hospital-Pavilion for Women</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>77520</td>\n",
       "      <td>US</td>\n",
       "      <td>201.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>28767.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19667.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>X</td>\n",
       "      <td>V239</td>\n",
       "      <td>64251</td>\n",
       "      <td>Y</td>\n",
       "      <td>64421</td>\n",
       "      <td>Y</td>\n",
       "      <td>65651</td>\n",
       "      <td>Y</td>\n",
       "      <td>65801</td>\n",
       "      <td>Y</td>\n",
       "      <td>V270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>7534.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7534.0</td>\n",
       "      <td>7534.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7534.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>765</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7300</td>\n",
       "      <td>0</td>\n",
       "      <td>1.596698e+09</td>\n",
       "      <td>1.596698e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120133877370</td>\n",
       "      <td>2013Q1</td>\n",
       "      <td>502000</td>\n",
       "      <td>Medical Center-Arlington</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>75163</td>\n",
       "      <td>US</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>59009.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48503.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>78609</td>\n",
       "      <td>42731</td>\n",
       "      <td>Y</td>\n",
       "      <td>42842</td>\n",
       "      <td>Y</td>\n",
       "      <td>4280</td>\n",
       "      <td>Y</td>\n",
       "      <td>4928</td>\n",
       "      <td>Y</td>\n",
       "      <td>2720</td>\n",
       "      <td>Y</td>\n",
       "      <td>4019</td>\n",
       "      <td>Y</td>\n",
       "      <td>V1582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7300</td>\n",
       "      <td>0</td>\n",
       "      <td>6.038903e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RECORD_ID DISCHARGE  THCIC_ID  \\\n",
       "0  420132203333    2013Q4    145000   \n",
       "1  220130397490    2013Q2    409000   \n",
       "2  120137915430    2013Q1    331000   \n",
       "3  420132272963    2013Q4    117100   \n",
       "4  120133877370    2013Q1    502000   \n",
       "\n",
       "                                 PROVIDER_NAME TYPE_OF_ADMISSION  \\\n",
       "0                    University Medical Center                 2   \n",
       "1                    John Peter Smith Hospital                 1   \n",
       "2             Baylor University Medical Center                 3   \n",
       "3  Texas Childrens Hospital-Pavilion for Women                 3   \n",
       "4                     Medical Center-Arlington                 1   \n",
       "\n",
       "  SOURCE_OF_ADMISSION SPEC_UNIT_1 SPEC_UNIT_2 SPEC_UNIT_3  SPEC_UNIT_4  \\\n",
       "0                   1         NaN         NaN         NaN          NaN   \n",
       "1                   1           I         NaN         NaN          NaN   \n",
       "2                   2         NaN         NaN         NaN          NaN   \n",
       "3                   1         NaN         NaN         NaN          NaN   \n",
       "4                   1           I         NaN         NaN          NaN   \n",
       "\n",
       "   SPEC_UNIT_5 PAT_STATE PAT_ZIP PAT_COUNTRY  COUNTY  PUBLIC_HEALTH_REGION  \\\n",
       "0          NaN        TX   79415          US   303.0                   1.0   \n",
       "1          NaN        TX   76054          US   439.0                   3.0   \n",
       "2          NaN        TX   75551          US    67.0                   4.0   \n",
       "3          NaN        TX   77520          US   201.0                   6.0   \n",
       "4          NaN        TX   75163          US   213.0                   4.0   \n",
       "\n",
       "  PAT_STATUS SEX_CODE RACE ETHNICITY  ADMIT_WEEKDAY  PAT_AGE  \\\n",
       "0         01        F  4.0         1              4        8   \n",
       "1         01        M  4.0         2              5        8   \n",
       "2         01        M  4.0         2              1       13   \n",
       "3         01        F  4.0         1              1        7   \n",
       "4         01        M  4.0         2              5       16   \n",
       "\n",
       "  FIRST_PAYMENT_SRC SECONDARY_PAYMENT_SRC  TYPE_OF_BILL  TOTAL_CHARGES  \\\n",
       "0                MC                    ZZ           111       16352.05   \n",
       "1                ZZ                   NaN           111       30650.00   \n",
       "2                BL                    CI           111       43770.01   \n",
       "3                MC                   NaN           111       28767.20   \n",
       "4                16                   NaN           111       59009.00   \n",
       "\n",
       "   TOTAL_NON_COV_CHARGES  TOTAL_CHARGES_ACCOMM  TOTAL_NON_COV_CHARGES_ACCOMM  \\\n",
       "0                    0.0                5555.0                           0.0   \n",
       "1                    0.0               10230.0                           0.0   \n",
       "2                    0.0                 581.7                           0.0   \n",
       "3                    0.0                9100.0                           0.0   \n",
       "4                    0.0               10506.0                           0.0   \n",
       "\n",
       "   TOTAL_CHARGES_ANCIL  TOTAL_NON_COV_CHARGES_ANCIL POA_PROVIDER_INDICATOR  \\\n",
       "0             10797.05                          0.0                      M   \n",
       "1             20420.00                          0.0                      M   \n",
       "2             43188.31                          0.0                      M   \n",
       "3             19667.20                          0.0                      X   \n",
       "4             48503.00                          0.0                      R   \n",
       "\n",
       "  ADMITTING_DIAGNOSIS PRINC_DIAG_CODE POA_PRINC_DIAG_CODE OTH_DIAG_CODE_1  \\\n",
       "0                V220           65981                   Y           65911   \n",
       "1               45386           45386                   Y            4019   \n",
       "2                 185             185                   Y           53085   \n",
       "3                V239           64251                   Y           64421   \n",
       "4               78609           42731                   Y           42842   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_1 OTH_DIAG_CODE_2 POA_OTH_DIAG_CODE_2 OTH_DIAG_CODE_3  \\\n",
       "0                   N           64891                   Y           66101   \n",
       "1                   Y            V141                 NaN            5259   \n",
       "2                   Y           53081                   Y           V1204   \n",
       "3                   Y           65651                   Y           65801   \n",
       "4                   Y            4280                   Y            4928   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_3 OTH_DIAG_CODE_4 POA_OTH_DIAG_CODE_4 OTH_DIAG_CODE_5  \\\n",
       "0                   N            7923                   N            V270   \n",
       "1                   Y           56400                   Y             490   \n",
       "2                 NaN           V1272                 NaN           V1501   \n",
       "3                   Y            V270                 NaN             NaN   \n",
       "4                   Y            2720                   Y            4019   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_5 OTH_DIAG_CODE_6 POA_OTH_DIAG_CODE_6 OTH_DIAG_CODE_7  \\\n",
       "0                 NaN           V0251                 NaN             NaN   \n",
       "1                   Y             NaN                 NaN             NaN   \n",
       "2                 NaN           V0254                 NaN            7871   \n",
       "3                 NaN             NaN                 NaN             NaN   \n",
       "4                   Y           V1582                 NaN             NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_7 OTH_DIAG_CODE_8 POA_OTH_DIAG_CODE_8 OTH_DIAG_CODE_9  \\\n",
       "0                 NaN             NaN                 NaN             NaN   \n",
       "1                 NaN             NaN                 NaN             NaN   \n",
       "2                   Y             NaN                 NaN             NaN   \n",
       "3                 NaN             NaN                 NaN             NaN   \n",
       "4                 NaN             NaN                 NaN             NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_9 OTH_DIAG_CODE_10 POA_OTH_DIAG_CODE_10 OTH_DIAG_CODE_11  \\\n",
       "0                 NaN              NaN                  NaN              NaN   \n",
       "1                 NaN              NaN                  NaN              NaN   \n",
       "2                 NaN              NaN                  NaN              NaN   \n",
       "3                 NaN              NaN                  NaN              NaN   \n",
       "4                 NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_11 OTH_DIAG_CODE_12 POA_OTH_DIAG_CODE_12 OTH_DIAG_CODE_13  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "3                  NaN              NaN                  NaN              NaN   \n",
       "4                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_13 OTH_DIAG_CODE_14 POA_OTH_DIAG_CODE_14 OTH_DIAG_CODE_15  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "3                  NaN              NaN                  NaN              NaN   \n",
       "4                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_15 OTH_DIAG_CODE_16 POA_OTH_DIAG_CODE_16 OTH_DIAG_CODE_17  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "3                  NaN              NaN                  NaN              NaN   \n",
       "4                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_17 OTH_DIAG_CODE_18 POA_OTH_DIAG_CODE_18 OTH_DIAG_CODE_19  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "3                  NaN              NaN                  NaN              NaN   \n",
       "4                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_19 OTH_DIAG_CODE_20 POA_OTH_DIAG_CODE_20 OTH_DIAG_CODE_21  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "3                  NaN              NaN                  NaN              NaN   \n",
       "4                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_21 OTH_DIAG_CODE_22 POA_OTH_DIAG_CODE_22 OTH_DIAG_CODE_23  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "3                  NaN              NaN                  NaN              NaN   \n",
       "4                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  POA_OTH_DIAG_CODE_23 OTH_DIAG_CODE_24 POA_OTH_DIAG_CODE_24 E_CODE_1  \\\n",
       "0                  NaN              NaN                  NaN      NaN   \n",
       "1                  NaN              NaN                  NaN      NaN   \n",
       "2                  NaN              NaN                  NaN      NaN   \n",
       "3                  NaN              NaN                  NaN      NaN   \n",
       "4                  NaN              NaN                  NaN      NaN   \n",
       "\n",
       "  POA_E_CODE_1 E_CODE_2 POA_E_CODE_2 E_CODE_3 POA_E_CODE_3 E_CODE_4  \\\n",
       "0          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "1          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "2          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "3          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "4          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "\n",
       "  POA_E_CODE_4 E_CODE_5 POA_E_CODE_5 E_CODE_6 POA_E_CODE_6 E_CODE_7  \\\n",
       "0          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "1          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "2          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "3          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "4          NaN      NaN          NaN      NaN          NaN      NaN   \n",
       "\n",
       "  POA_E_CODE_7 E_CODE_8 POA_E_CODE_8  E_CODE_9  POA_E_CODE_9  E_CODE_10  \\\n",
       "0          NaN      NaN          NaN       NaN           NaN        NaN   \n",
       "1          NaN      NaN          NaN       NaN           NaN        NaN   \n",
       "2          NaN      NaN          NaN       NaN           NaN        NaN   \n",
       "3          NaN      NaN          NaN       NaN           NaN        NaN   \n",
       "4          NaN      NaN          NaN       NaN           NaN        NaN   \n",
       "\n",
       "   POA_E_CODE_10 PRINC_SURG_PROC_CODE  PRINC_SURG_PROC_DAY PRINC_ICD9_CODE  \\\n",
       "0            NaN                734.0                  1.0           734.0   \n",
       "1            NaN                  NaN                  NaN             NaN   \n",
       "2            NaN                605.0                  0.0           605.0   \n",
       "3            NaN                741.0                  2.0           741.0   \n",
       "4            NaN                  NaN                  NaN             NaN   \n",
       "\n",
       "  OTH_SURG_PROC_CODE_1  OTH_SURG_PROC_DAY_1 OTH_ICD9_CODE_1  \\\n",
       "0                741.0                  1.0           741.0   \n",
       "1                  NaN                  NaN             NaN   \n",
       "2                403.0                  0.0           403.0   \n",
       "3               7534.0                  0.0          7534.0   \n",
       "4                  NaN                  NaN             NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_2  OTH_SURG_PROC_DAY_2  OTH_ICD9_CODE_2  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                1742.0                  0.0           1742.0   \n",
       "3                7534.0                  1.0           7534.0   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_3  OTH_SURG_PROC_DAY_3  OTH_ICD9_CODE_3  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_4  OTH_SURG_PROC_DAY_4  OTH_ICD9_CODE_4  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_5  OTH_SURG_PROC_DAY_5  OTH_ICD9_CODE_5  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_6  OTH_SURG_PROC_DAY_6  OTH_ICD9_CODE_6  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_7  OTH_SURG_PROC_DAY_7  OTH_ICD9_CODE_7  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_8  OTH_SURG_PROC_DAY_8  OTH_ICD9_CODE_8  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_9  OTH_SURG_PROC_DAY_9  OTH_ICD9_CODE_9  \\\n",
       "0                   NaN                  NaN              NaN   \n",
       "1                   NaN                  NaN              NaN   \n",
       "2                   NaN                  NaN              NaN   \n",
       "3                   NaN                  NaN              NaN   \n",
       "4                   NaN                  NaN              NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_10  OTH_SURG_PROC_DAY_10  OTH_ICD9_CODE_10  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_11  OTH_SURG_PROC_DAY_11  OTH_ICD9_CODE_11  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_12  OTH_SURG_PROC_DAY_12  OTH_ICD9_CODE_12  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_13  OTH_SURG_PROC_DAY_13  OTH_ICD9_CODE_13  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_14  OTH_SURG_PROC_DAY_14  OTH_ICD9_CODE_14  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_15  OTH_SURG_PROC_DAY_15  OTH_ICD9_CODE_15  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_16  OTH_SURG_PROC_DAY_16  OTH_ICD9_CODE_16  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_17  OTH_SURG_PROC_DAY_17  OTH_ICD9_CODE_17  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_18  OTH_SURG_PROC_DAY_18  OTH_ICD9_CODE_18  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_19  OTH_SURG_PROC_DAY_19  OTH_ICD9_CODE_19  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_20  OTH_SURG_PROC_DAY_20  OTH_ICD9_CODE_20  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_21  OTH_SURG_PROC_DAY_21  OTH_ICD9_CODE_21  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_22  OTH_SURG_PROC_DAY_22  OTH_ICD9_CODE_22  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_23  OTH_SURG_PROC_DAY_23  OTH_ICD9_CODE_23  \\\n",
       "0                    NaN                   NaN               NaN   \n",
       "1                    NaN                   NaN               NaN   \n",
       "2                    NaN                   NaN               NaN   \n",
       "3                    NaN                   NaN               NaN   \n",
       "4                    NaN                   NaN               NaN   \n",
       "\n",
       "   OTH_SURG_PROC_CODE_24  OTH_SURG_PROC_DAY_24  OTH_ICD9_CODE_24  MS_MDC  \\\n",
       "0                    NaN                   NaN               NaN      14   \n",
       "1                    NaN                   NaN               NaN       5   \n",
       "2                    NaN                   NaN               NaN      12   \n",
       "3                    NaN                   NaN               NaN      14   \n",
       "4                    NaN                   NaN               NaN       5   \n",
       "\n",
       "   MS_DRG  MS_GROUPER_VERSION_NBR  MS_GROUPER_ERROR_CODE  APR_MDC  APR_DRG  \\\n",
       "0     766                    1300                      0       14      540   \n",
       "1     301                    1300                      0        5      197   \n",
       "2     708                    1300                      0       12      480   \n",
       "3     765                    1300                      0       14      540   \n",
       "4     309                    1300                      0        5      201   \n",
       "\n",
       "   RISK_MORTALITY  ILLNESS_SEVERITY  APR_GROUPER_VERSION_NBR  \\\n",
       "0               1                 2                     7300   \n",
       "1               1                 1                     7300   \n",
       "2               1                 2                     7300   \n",
       "3               1                 3                     7300   \n",
       "4               2                 2                     7300   \n",
       "\n",
       "   APR_GROUPER_ERROR_CODE  ATTENDING_PHYSICIAN_UNIF_ID  \\\n",
       "0                       0                 1.054183e+09   \n",
       "1                       0                 1.273456e+09   \n",
       "2                       0                 1.318271e+09   \n",
       "3                       0                 1.596698e+09   \n",
       "4                       0                 6.038903e+09   \n",
       "\n",
       "   OPERATING_PHYSICIAN_UNIF_ID  ENCOUNTER_INDICATOR  CERT_STATUS  FILLER_SPACE  \n",
       "0                 1.401552e+09                    1            2           NaN  \n",
       "1                          NaN                    1            2           NaN  \n",
       "2                 1.318271e+09                    1            2           NaN  \n",
       "3                 1.596698e+09                    1            1           NaN  \n",
       "4                          NaN                    1            1           NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grading = pd.read_csv(f\"{ROOT}/orig/grading.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "print(df_grading.shape)\n",
    "df_grading.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b91762e6-1675-40d7-a158-4ed604d56762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 199939 entries, 992358 to 410879\n",
      "Data columns (total 43 columns):\n",
      " #   Column                     Non-Null Count   Dtype   \n",
      "---  ------                     --------------   -----   \n",
      " 0   TYPE_OF_ADMISSION          199939 non-null  category\n",
      " 1   SOURCE_OF_ADMISSION        199939 non-null  category\n",
      " 2   PAT_STATE                  199939 non-null  category\n",
      " 3   PAT_COUNTRY                199939 non-null  category\n",
      " 4   PUBLIC_HEALTH_REGION       199939 non-null  category\n",
      " 5   SEX_CODE                   199939 non-null  category\n",
      " 6   RACE                       199939 non-null  category\n",
      " 7   ETHNICITY                  199939 non-null  category\n",
      " 8   ADMIT_WEEKDAY              199939 non-null  category\n",
      " 9   ADMITTING_DIAGNOSIS        199674 non-null  object  \n",
      " 10  PRINC_DIAG_CODE            199939 non-null  object  \n",
      " 11  POA_PRINC_DIAG_CODE        156951 non-null  object  \n",
      " 12  TARGET                     199939 non-null  category\n",
      " 13  PROVIDER_NAME_col_0        199939 non-null  category\n",
      " 14  PROVIDER_NAME_col_1        199939 non-null  category\n",
      " 15  PROVIDER_NAME_col_2        199939 non-null  category\n",
      " 16  PROVIDER_NAME_col_3        199939 non-null  category\n",
      " 17  PROVIDER_NAME_col_4        199939 non-null  category\n",
      " 18  PROVIDER_NAME_col_5        199939 non-null  category\n",
      " 19  PROVIDER_NAME_col_6        199939 non-null  category\n",
      " 20  COUNTY_col_0               199939 non-null  category\n",
      " 21  COUNTY_col_1               199939 non-null  category\n",
      " 22  COUNTY_col_2               199939 non-null  category\n",
      " 23  COUNTY_col_3               199939 non-null  category\n",
      " 24  COUNTY_col_4               199939 non-null  category\n",
      " 25  COUNTY_col_5               199939 non-null  category\n",
      " 26  COUNTY_col_6               199939 non-null  category\n",
      " 27  ADMITTING_DIAGNOSIS_col_0  199939 non-null  category\n",
      " 28  ADMITTING_DIAGNOSIS_col_1  199939 non-null  category\n",
      " 29  ADMITTING_DIAGNOSIS_col_2  199939 non-null  category\n",
      " 30  ADMITTING_DIAGNOSIS_col_3  199939 non-null  category\n",
      " 31  ADMITTING_DIAGNOSIS_col_4  199939 non-null  category\n",
      " 32  ADMITTING_DIAGNOSIS_col_5  199939 non-null  category\n",
      " 33  ADMITTING_DIAGNOSIS_col_6  199939 non-null  category\n",
      " 34  PRINC_DIAG_CODE_col_0      199939 non-null  category\n",
      " 35  PRINC_DIAG_CODE_col_1      199939 non-null  category\n",
      " 36  PRINC_DIAG_CODE_col_2      199939 non-null  category\n",
      " 37  PRINC_DIAG_CODE_col_3      199939 non-null  category\n",
      " 38  PRINC_DIAG_CODE_col_4      199939 non-null  category\n",
      " 39  PRINC_DIAG_CODE_col_5      199939 non-null  category\n",
      " 40  PRINC_DIAG_CODE_col_6      199939 non-null  category\n",
      " 41  POA_OTH_DIAG_CODE_COUNT    199939 non-null  int64   \n",
      " 42  POA_E_CODE_COUNT           199939 non-null  int64   \n",
      "dtypes: category(38), int64(2), object(3)\n",
      "memory usage: 16.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cfdf4a3",
   "metadata": {},
   "source": [
    "### Specifying Feature and Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7a8b17c-1012-4144-94b1-fce8ca95cf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TYPE_OF_ADMISSION',\n",
       " 'SOURCE_OF_ADMISSION',\n",
       " 'PAT_STATE',\n",
       " 'PUBLIC_HEALTH_REGION',\n",
       " 'ADMITTING_DIAGNOSIS',\n",
       " 'PRINC_DIAG_CODE',\n",
       " 'POA_PRINC_DIAG_CODE',\n",
       " 'ADMIT_WEEKDAY']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=\"TARGET\"\n",
    "\n",
    "#cat_features = [catFeature for catFeature in df.select_dtypes(\"category\").columns if catFeature not in target]\n",
    "\n",
    "#print(cat_features)\n",
    "\n",
    "cat_features=[\n",
    "    \"TYPE_OF_ADMISSION\",\n",
    "    \"SOURCE_OF_ADMISSION\",\n",
    "    \"PAT_STATE\",\n",
    "    \"PUBLIC_HEALTH_REGION\",\n",
    "    \"ADMITTING_DIAGNOSIS\",\n",
    "    \"PRINC_DIAG_CODE\",\n",
    "    \"POA_PRINC_DIAG_CODE\",\n",
    "    \"ADMIT_WEEKDAY\",\n",
    "    #\"SEX_CODE\",\n",
    "    #\"RACE\"\n",
    "]\n",
    "\n",
    "#num_features=[numFeature for numFeature in df.select_dtypes(\"int\").columns if numFeature not in target]\n",
    "\n",
    "num_features=[]\n",
    "\n",
    "features= cat_features + num_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8728093d",
   "metadata": {},
   "source": [
    "### Creating Categorical and Numerical Transformers for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b98c4a7-3880-4381-8852-d5d45b046004",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('selector', SelectPercentile(chi2,percentile=80)),\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat',cat_transformer,cat_features),\n",
    "    ('num',num_transformer,num_features),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e631eb18",
   "metadata": {},
   "source": [
    "### Specifying Models for Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2c0220a-df55-493a-a6e4-b4b00d1b9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    #\"LR\": LogisticRegression(max_iter=1000),\n",
    "    #\"DT\": DecisionTreeClassifier(),\n",
    "    #\"KNN\": KNeighborsClassifier(),\n",
    "    #\"RF\": RandomForestClassifier(),\n",
    "    #\"ET\": ExtraTreesClassifier(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "    #\"LGBM\": LGBMClassifier(),\n",
    "    #\"CB\": CatBoostClassifier(silent=True),\n",
    "    #\"ADA\": AdaBoostClassifier(n_estimators=100,random_state=SEED),\n",
    "    #\"GBRT\": GradientBoostingClassifier(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42) \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cf3e8bb",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ed8b246-acf1-4332-a023-750081488b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119963, 8), (79976, 8))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.4, random_state=SEED)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd96fbf",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0448d83b-f651-40b6-8b94-a2afab3ed9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy: 0.57 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(name, \"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9002b84c",
   "metadata": {},
   "source": [
    "- LR Accuracy: 0.49 (+/- 0.01)\n",
    "- DT Accuracy: 0.48 (+/- 0.00)\n",
    "- KNN Accuracy: 0.43 (+/- 0.01)\n",
    "- RF Accuracy: 0.48 (+/- 0.00)\n",
    "- ET Accuracy: 0.48 (+/- 0.00)\n",
    "- XGB Accuracy: 0.50 (+/- 0.01)\n",
    "- LGBM Accuracy: 0.50 (+/- 0.00)\n",
    "- CB Accuracy: 0.50 (+/- 0.00)\n",
    "- ADA Accuracy: 0.49 (+/- 0.01)\n",
    "- GBRT Accuracy: 0.49 (+/- 0.01)\n",
    "\n",
    "##### As we can see from the models above XGB, LGBM and CB give use the best results we will use XGB moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c0b39b0-2d93-45fe-8265-11a2dfbdf400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE_OF_ADMISSION</th>\n",
       "      <th>SOURCE_OF_ADMISSION</th>\n",
       "      <th>PAT_STATE</th>\n",
       "      <th>PUBLIC_HEALTH_REGION</th>\n",
       "      <th>ADMITTING_DIAGNOSIS</th>\n",
       "      <th>PRINC_DIAG_CODE</th>\n",
       "      <th>POA_PRINC_DIAG_CODE</th>\n",
       "      <th>ADMIT_WEEKDAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632486</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>03</td>\n",
       "      <td>99649</td>\n",
       "      <td>99649</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353811</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>05</td>\n",
       "      <td>4439</td>\n",
       "      <td>44020</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188575</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>01</td>\n",
       "      <td>41071</td>\n",
       "      <td>41071</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151440</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>06</td>\n",
       "      <td>V5789</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732852</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>06</td>\n",
       "      <td>5362</td>\n",
       "      <td>5363</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488104</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>TX</td>\n",
       "      <td>03</td>\n",
       "      <td>V3001</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874523</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>04</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715832</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>06</td>\n",
       "      <td>28262</td>\n",
       "      <td>28242</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783859</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>09</td>\n",
       "      <td>650</td>\n",
       "      <td>64421</td>\n",
       "      <td>Y</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>03</td>\n",
       "      <td>78909</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119963 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TYPE_OF_ADMISSION SOURCE_OF_ADMISSION PAT_STATE PUBLIC_HEALTH_REGION  \\\n",
       "632486                 3                   2        TX                   03   \n",
       "353811                 3                   2        TX                   05   \n",
       "188575                 1                   1        TX                   01   \n",
       "151440                 3                   4        TX                   06   \n",
       "732852                 1                   1        TX                   06   \n",
       "...                  ...                 ...       ...                  ...   \n",
       "488104                 4                   5        TX                   03   \n",
       "874523                 1                   1        TX                   04   \n",
       "715832                 1                   1        TX                   06   \n",
       "783859                 2                   1        TX                   09   \n",
       "53938                  2                   1        TX                   03   \n",
       "\n",
       "       ADMITTING_DIAGNOSIS PRINC_DIAG_CODE POA_PRINC_DIAG_CODE ADMIT_WEEKDAY  \n",
       "632486               99649           99649                   Y             5  \n",
       "353811                4439           44020                   Y             4  \n",
       "188575               41071           41071                   Y             3  \n",
       "151440               V5789               U                 NaN             2  \n",
       "732852                5362            5363                   Y             4  \n",
       "...                    ...             ...                 ...           ...  \n",
       "488104               V3001               U                 NaN             1  \n",
       "874523                 486             486                   Y             5  \n",
       "715832               28262           28242                   Y             4  \n",
       "783859                 650           64421                   Y             7  \n",
       "53938                78909               U                 NaN             2  \n",
       "\n",
       "[119963 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessor.fit(X_train,y_train)\n",
    "#preprocessor.transform(X_train)\n",
    "#preprocessor.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7910e5af",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d0306f1-53c1-485c-be4e-5117ff730bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('XGB', XGBClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c683dd92-c559-400d-96c2-0931cc2c41fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                                                  (&#x27;selector&#x27;,\n",
       "                                                                   SelectPercentile(percentile=80,\n",
       "                                                                                    score_func=&lt;function chi2 at 0x7feec4ca00d0&gt;))]),\n",
       "                                                  [&#x27;TYPE_OF_ADMISSION&#x27;,\n",
       "                                                   &#x27;SOURCE_OF_ADMISSION&#x27;,\n",
       "                                                   &#x27;PAT_STATE&#x27;,\n",
       "                                                   &#x27;PUBLIC_HEALTH_R...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                                                  (&#x27;selector&#x27;,\n",
       "                                                                   SelectPercentile(percentile=80,\n",
       "                                                                                    score_func=&lt;function chi2 at 0x7feec4ca00d0&gt;))]),\n",
       "                                                  [&#x27;TYPE_OF_ADMISSION&#x27;,\n",
       "                                                   &#x27;SOURCE_OF_ADMISSION&#x27;,\n",
       "                                                   &#x27;PAT_STATE&#x27;,\n",
       "                                                   &#x27;PUBLIC_HEALTH_R...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                                 (&#x27;selector&#x27;,\n",
       "                                                  SelectPercentile(percentile=80,\n",
       "                                                                   score_func=&lt;function chi2 at 0x7feec4ca00d0&gt;))]),\n",
       "                                 [&#x27;TYPE_OF_ADMISSION&#x27;, &#x27;SOURCE_OF_ADMISSION&#x27;,\n",
       "                                  &#x27;PAT_STATE&#x27;, &#x27;PUBLIC_HEALTH_REGION&#x27;,\n",
       "                                  &#x27;ADMITTING_DIAGNOSIS&#x27;, &#x27;PRINC_DIAG_CODE&#x27;,\n",
       "                                  &#x27;POA_PRINC_DIAG_CODE&#x27;, &#x27;ADMIT_WEEKDAY&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TYPE_OF_ADMISSION&#x27;, &#x27;SOURCE_OF_ADMISSION&#x27;, &#x27;PAT_STATE&#x27;, &#x27;PUBLIC_HEALTH_REGION&#x27;, &#x27;ADMITTING_DIAGNOSIS&#x27;, &#x27;PRINC_DIAG_CODE&#x27;, &#x27;POA_PRINC_DIAG_CODE&#x27;, &#x27;ADMIT_WEEKDAY&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=80, score_func=&lt;function chi2 at 0x7feec4ca00d0&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                  ('selector',\n",
       "                                                                   SelectPercentile(percentile=80,\n",
       "                                                                                    score_func=<function chi2 at 0x7feec4ca00d0>))]),\n",
       "                                                  ['TYPE_OF_ADMISSION',\n",
       "                                                   'SOURCE_OF_ADMISSION',\n",
       "                                                   'PAT_STATE',\n",
       "                                                   'PUBLIC_HEALTH_R...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective='multi:softprob', predictor=None, ...))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c51d9cb7-bf65-4b7d-8e50-41a2affc778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.34      0.46     24526\n",
      "           1       0.50      0.73      0.60     45874\n",
      "           2       0.70      0.59      0.64     49563\n",
      "\n",
      "    accuracy                           0.59    119963\n",
      "   macro avg       0.64      0.55      0.56    119963\n",
      "weighted avg       0.63      0.59      0.59    119963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0df91b2",
   "metadata": {},
   "source": [
    "##### Basic model with preprocessing gives us a score of 60% we will attempt to use different methods to increases this score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b2367cd",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a897d1b-12bc-4c76-aa31-0c64c7d31c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'XGB__learning_rate': [0.01, 0.1, 0.5],\n",
    "    'XGB__max_depth': [3, 5, 7],\n",
    "    'XGB__n_estimators': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print(\"Best parameters:\", grid_search.best_params_)\n",
    "#print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43b26d-caee-4833-bfbc-f7ba88353887",
   "metadata": {},
   "source": [
    "Best parameters: {'XGB__learning_rate': 0.5, 'XGB__max_depth': 3, 'XGB__n_estimators': 500}\n",
    "Best score: 0.5722681188815673"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edb5b3a9",
   "metadata": {},
   "source": [
    "##### Using grid search we were able to find the best parameters for the XGB classifier and will use it in a new model to see if it has improved our score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f322f75",
   "metadata": {},
   "source": [
    "### 2nd Model - Using Opimised Parameters from Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d117704e-5ff7-42ec-a9b2-eba64a8a2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.41      0.51     24526\n",
      "           1       0.53      0.68      0.60     45874\n",
      "           2       0.70      0.65      0.67     49563\n",
      "\n",
      "    accuracy                           0.61    119963\n",
      "   macro avg       0.63      0.58      0.59    119963\n",
      "weighted avg       0.63      0.61      0.61    119963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('XGB', XGBClassifier(learning_rate=0.5, max_depth=3, n_estimators=500)),\n",
    "])\n",
    "\n",
    "model2.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model2.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1a5472d",
   "metadata": {},
   "source": [
    "##### optimising the parameters for XGB has increased our best score by 2% we will use these new parameters moving forward and attempt to improve it further"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90b6ac00",
   "metadata": {},
   "source": [
    "### Checking Target Value Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64b7bd9d-c01b-454c-9ae5-d96faf356364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = pd.Series(y_train).value_counts()\n",
    "\n",
    "# Create a bar chart to visualize the class distribution\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(class_counts.index)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1055916",
   "metadata": {},
   "source": [
    "##### From the graph above we can see that the 0 value has a lower count compared to 2 and 3 which are reasonabily close. We will balance this data out using SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bb0309f",
   "metadata": {},
   "source": [
    "### 3rd Model - Balancing Data Using Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d0eea6a-2754-4da0-ae73-5d9ee7a98e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote',SMOTE(random_state=SEED)),\n",
    "    ('Classifier', XGBClassifier(learning_rate=0.5, max_depth=3, n_estimators=500))\n",
    "])\n",
    "\n",
    "# model3.fit(X_train,y_train)\n",
    "\n",
    "# y_pred = model3.predict(X_train)\n",
    "\n",
    "# print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70f35ac1",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.60      0.48      0.53     24526\n",
    "           1       0.53      0.66      0.59     45874\n",
    "           2       0.71      0.61      0.66     49563\n",
    "\n",
    "    accuracy                           0.60    119963\n",
    "   macro avg       0.61      0.58      0.59    119963\n",
    "weighted avg       0.61      0.60      0.60    119963"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f771592",
   "metadata": {},
   "source": [
    "##### Our accuracy score has decrease by 1% while using smote, we will leave smote out from our pipelines moving forward."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80e19dd9",
   "metadata": {},
   "source": [
    "### 4th Model - Using Stacked Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "446b41c4-3d18-4d33-a78b-1ce673fdbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_0_models = {\n",
    "    \"XGB\": XGBClassifier(learning_rate=0.5, max_depth=3, n_estimators=500),\n",
    "    \"LGBM\": LGBMClassifier(),\n",
    "    \"CB\": CatBoostClassifier(silent=True),\n",
    "}\n",
    "\n",
    "level_1_model = XGBClassifier(learning_rate=0.5, max_depth=3, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "673a8630-85d0-4b36-abbe-e680519ca578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.45      0.54     24526\n",
      "           1       0.54      0.67      0.60     45874\n",
      "           2       0.70      0.66      0.68     49563\n",
      "\n",
      "    accuracy                           0.62    119963\n",
      "   macro avg       0.64      0.59      0.61    119963\n",
      "weighted avg       0.63      0.62      0.62    119963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "model4 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking',StackingClassifier( estimators=list(level_0_models.items()), final_estimator=level_1_model, \n",
    "    passthrough=True, cv=cv, stack_method=\"predict_proba\"))\n",
    "])\n",
    "\n",
    "model4.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model4.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train,y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fed4e11c",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.67      0.45      0.54     24526\n",
    "           1       0.54      0.67      0.60     45874\n",
    "           2       0.70      0.66      0.68     49563\n",
    "\n",
    "    accuracy                           0.62    119963\n",
    "   macro avg       0.64      0.59      0.61    119963\n",
    "weighted avg       0.63      0.62      0.62    119963"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26de1433",
   "metadata": {},
   "source": [
    "##### Using the top 3 models from model selection as our level 0 models in combination with our XGB classifier with optimised parameters has further improved our score by 1%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f172d50a",
   "metadata": {},
   "source": [
    "### Saving Model for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bf916cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.sav']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model4,\"model.sav\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cb8bc11",
   "metadata": {},
   "source": [
    "### Generating Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f8c06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model4.predict(df_grading)\n",
    "\n",
    "df_grading_pred = pd.DataFrame({'TARGET': predictions}, index=df_grading.index)\n",
    "\n",
    "#df_grading_pred = pd.DataFrame({'TARGET': predictions}, index=df_grading['RECORD_ID'])\n",
    "\n",
    "df_grading_pred.to_csv('df_grading_pred.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aee19a7f",
   "metadata": {},
   "source": [
    "### Creating Archive with files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6ba232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating archive: my_assignment.zip\n",
      "\tdf_grading_pred.csv - OK\n",
      "\t01-Import.ipynb - OK\n",
      "\t02-EDA.ipynb - OK\n",
      "\tdashboard.py - OK\n",
      "\tmy_lib.py - OK\n",
      "\t03-Model.ipynb - OK\n"
     ]
    }
   ],
   "source": [
    "my_lib.make_assignment()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1776e0ac",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We managed to improve our base model from 50% to 62%. This was done by:\n",
    "\n",
    "- Adding the features below improved our model by +9% : \n",
    "    - \"ADMITTING_DIAGNOSIS\"\n",
    "    - \"PRINC_DIAG_CODE\"\n",
    "    - \"POA_PRINC_DIAG_CODE\"\n",
    "    - \"ADMIT_WEEKDAY\"\n",
    "\n",
    "\n",
    "- Utilizing GridSearch to find the best parameters for the XGB classifier, resulting in an additional 2% improvement.\n",
    "\n",
    "- Implementing a Stacked Learner approach by combining the predictions of the top 3 classifiers, which further improved the accuracy by 1%.\n",
    "\n",
    "Overall, these enhancements helped us achieve a significant boost in the model's performance, increasing the accuracy from 50% to 62%.\n",
    "\n",
    "Using SMOTE decreased our score by -1%\n",
    "\n",
    "When the two features below were added our base model reached 60% compared to the 59% without these features,however the scores in the end were the same as the stacked learner didnt improve the score at all in this case. I chose to use less features and maintain the same score by using stacked learners.\n",
    "\n",
    "- \"SEX_CODE\"\n",
    "- \"RACE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30131bb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
